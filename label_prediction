#!pip3 install pymystem3
import pandas as pd
from pymystem3 import Mystem
from tqdm import tqdm
tqdm.pandas()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

xls = pd.ExcelFile('for_hack_2.xlsx')
df_data = pd.read_excel(xls, sheet_name="data")

#не будем использовать для предсказания

first_drop = df_data[(df_data['Вид экстремизма'].isnull())|(df_data['Вид экстремизма']=='???')
       |(df_data['Вид экстремизма']=='Все сразу')|(df_data['Вид экстремизма']=='not identified')]
first_drop

for_model = df_data.drop(first_drop.index)

#лемматизируем для модели описания материалов и выбросим стоп-слова:

m = Mystem(disambiguation=True)

st = pd.read_html('https://github.com/tsekh93/russian_stopwords/blob/main/final_stop.txt')[0][1].reset_index()
stopwords = list(st[1])

def lemmatizer(text):
    try:
        lemmas = []
        for word_info in m.analyze(text):
            if 'analysis' in word_info and len(word_info['analysis']) > 0 and word_info['analysis'][0]['lex'] not in stopwords:
                lemma = word_info['analysis'][0]['lex']
            lemmas.append(lemma)
        return ' '.join(list(set(lemmas)))
    except:
        return text
        
for_model['lemmatized'] = for_model['original'].progress_apply(lemmatizer)

#посмотрим, что не лемматизировалось:

for_model[for_model['lemmatized'].isnull()]

#тоже выкинем их:

second_drop = for_model[for_model['lemmatized'].isnull()]

#итоговая таблица:
for_model_2 = for_model.drop(second_drop.index)

#выкинем колонки с номерами:
for_model_2 = for_model_2.drop(columns=['№№', '№'])

for_model_2['date_of_design'] = pd.to_datetime(for_model_2['date_of_design'])
for_model_2['add_date'] = pd.to_datetime(for_model_2['add_date'])

# делим на обучающую и тестовую выборки:

X = for_model_2['lemmatized']
y = for_model_2['Вид экстремизма']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4345)

#мешок слов

cv = CountVectorizer()
X_train_cv = cv.fit_transform(X_train)

#логистическая регрессия

lr = LogisticRegression()
#фитим тренировочные
lr.fit(X_train_cv, y_train)
#трансформируем тестовые:

X_test_cv = cv.transform(X_test)

#предсказания

predictions = lr.predict(X_test_cv)

print(classification_report(y_test, predictions))

# сделаем предсказание для записей без меток:

#лемматизируем тексты в том сабсете:
first_drop = first_drop.drop(columns=['№№', '№', 'Вид экстремизма'])

first_drop['lemmatized'] = first_drop['original'].progress_apply(lemmatizer)

#предсказание:
new = cv.transform(first_drop['lemmatized'])
lr.predict(new)

first_drop['predicted'] = lr.predict(new)

